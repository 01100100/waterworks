# Waterworks 🌊

This is a dbt project to model data from [Kreuzungen](https://github.com/01100100/kreuzungen). 

Everytime kreuzungen analyizes a strava activiy, event data is stored in a Tigris S3 bucket for further analysis and processing.

This dbt project builds a geospatial data warehouse from the data using the [DuckDB](https://duckdb.org/) dbt adapter [dbt-duckdb](https://github.com/duckdb/dbt-duckdb) and the official [spatial extension](https://duckdb.org/docs/extensions/spatial), which heavy relies on [GDAL](https://gdal.org/).

The data models produces ephemeral and materialized tables which are persisted as JSON files, stored in a [Tigris](https://www.tigrisdata.com/) S3 bucket.

It uses incremental models to only process new data and only fetch data from Nominatim when absolutely necessary. Models are designed to be idempotent, to ensure that the data is always in a consistent state and the models can be run multiple times without side effects.

## Features ✨

- 🌐 **Enriched OSM data** thanks to [Nominatim](https://nominatim.org/).
- 📊 **Outputted aggregated data** per country data to show the number of rivers crossed.
- 📄 [**Autogenerated documentation**](https://01100100.github.io/waterworks/) using [dbt docs](https://docs.getdbt.com/docs/introduction) hosted on github pages.
- 🚀 **CI/CD** using GitHub Actions to handel deployments based on git-ops.
- ⏲️ **Scheduled dbt runs** using scheduled Fly.io machines.
- 💽 **Cloud optimized data** thanks to [Parquet](https://parquet.apache.org/) and [DuckDB](https://duckdb.org/).
- 💸 **Wallet-friendly** thanks to no Egrees fees between [Fly.io](fly.io) and [Tigris](https://www.tigrisdata.com/).

## Quick start 🚀

1. Clone this repository

```bash
git clone https://github.com/01100100/waterworks.git
```

2. Create virtual environment

```bash
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

3. Run dbt commands

```bash
dbt source freshness
dbt build
dbt docs generate
dbt docs run
```

NOTE: This will create a local DuckDB database `./dbt.duckdb` that stores intermediate tables. This is useful for data exploration and debugging.

```
duckdb ./dbt.duckdb
```

4. A full refresh can
## Data sources and models 🪣

All data sources and models are defined in the `models/` directory, either in the `sources.yml` or `models/` directory in a `.sql` or `.py` file. Configuration for the project is defined in `dbt_project.yml` and connection information is stored in `profiles.yml`.

## DBT Docs 📚

The documentation for this project is hosted on GitHub Pages. You can view it [here](https://01100100.github.io/waterworks/).

## Deployment 📦

This project uses GitHub Actions for CI. The workflow is defined in `.github/workflows/ci.yml`.

There are two jobs in the workflow:

1. **docs** runs `dbt build` and `dbt docs generate` to build the data warehouse and generate documentation, then uses GitHub Pages to host the documentation.
2. **fly-deploy** triggers a Fly deployment and creates a scheduled job to run `dbt build` every hour.

## Fly.io Deployment 🛠

To start a shell session on a fly machine using the dbt environment and enough memory, run:

```bash
fly machine run . -a waterworks --shell -c fly.toml --vm-memory 8192 --vm-cpu-kind performance
```

This will use the `fly.toml` configuration file to set up the machine based on the Dockerfile. The `--vm-memory` and `--vm-cpu-kind` flags set the memory and CPU requirements and can be adjusted based on how much data is being processed.

To schedule a dbt run on a fly machine, run:

```bash
fly machine run . -a waterworks -c fly.toml --vm-memory 8192 --vm-cpu-kind performance --region ams
```

NOTE:

- The `--vm-memory` and `--vm-cpu-kind` flags are optional 

### Monitoring 📈

The [Fly.io Grafana dashboard](https://fly-metrics.net/d/fly-app/fly-app?orgId=151889&var-app=waterworks) can be used to monitor the machine and the dbt runs.


